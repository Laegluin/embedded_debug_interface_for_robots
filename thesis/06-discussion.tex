\chapter{Discussion}
\label{discussion}

This chapter discusses the results gathered from the experiments that were presented and evaluated in
chapter \ref{evaluation}.
\bigbreak

All of the experiments except for \ref{evaluation/results/synthetic-ping-instructions-no-delay} and
\ref{evaluation/results/synthetic-ping-instructions-100us-delay} showed a maximum \textit{time between buffers}
of below or slightly above \SI{16}{\milli\second}. This means that in practice, the implementation is
performant enough to not lose any data, especially considering that a bus load of \SI{100}{\percent}
is not possible in reality.

It is clear that there is a constant overhead of about \SI{4}{\milli\second} in the
\textit{time between buffers}. This overhead can be seen as the median \textit{time between buffers}
in all experiments. This overhead is not small; compared to the approximate maximum of \SI{16}{\milli\second},
it is \SI{25}{\percent} of the entire time spent.

From both experiments that used synthetic \textit{Ping} instructions as data it is apparent that
\textit{Ping} instructions are the absolute worst case when it comes to processing time. This is
not surprising considering that \textit{Ping} instructions may require allocating a new
\lstinline{ControlTable} object (see subsection \ref{implementation/software/packet-processing-task}).
However, these allocations are only necessary when the model number changes constantly as was the case
in these two experiments. This is simply not a realistic scenario; in practice, \textit{Ping} instructions
are incredible rare, usually only sent when the master connects to the bus for the first time.

The number of \textit{Ping} instructions in the other experiments was already higher than to be expected
because the data they used contained at least one \textit{Ping} instruction and response for every device.
This means that \textit{Ping} instructions were sent every time the data was repeated. This unusually
high frequency did not impact performance in any meaningful way, however. All four experiments processed
the incoming data in time.

Generally, the amount of load on the bus was noticeable when interacting with the UI. It manifested
as periodic increases in latency and low framerate. These became especially severe when the load was
too high to be processed in time.

This is a direct consequence of how the UI and the data processing task are configured. Since the UI
task is only assigned a fixed amount of time after all incoming data in one half of the buffer has
been processed, higher processing times decrease the overall amount time spent updating the UI (see
subsection \ref{implementation/software/overview} for details).

While this only seriously affected the UI once incoming data was already getting lost, the user
experience was still not acceptable. There is certainly room for improvement, either by optimizing
the firmware, redesigning the way the priorities of the two tasks are handled or by switching to
hardware with greater processing power.
